# Awesome-RL-Reasoning

[![PR Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen)](https://github.com/bruno686/Awesome-RL-based-LLM-Reasoning/pulls)
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

## Papers

### Algorithm

- (2025.08) [Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning](https://arxiv.org/abs/2508.09726)
- (2025.08) [Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://arxiv.org/abs/2508.08221)
- (2025.07) [Group Sequence Policy Optimization](https://arxiv.org/abs/2507.18071)
- (2025.06) [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050)
- (2025.04) [VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks](https://arxiv.org/abs/2504.05118)
- (2025.03) [Understanding R1-Zero-Like Training: A Critical Perspective](https://arxiv.org/abs/2503.20783)
- (2025.03) [DAPO: An Open-Source LLM Reinforcement Learning System at Scale](https://arxiv.org/abs/2503.14476)
- (2024.02) [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300)

### Scaling

- (2025.06) [AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy](https://arxiv.org/abs/2506.13284)
- (2025.05) [ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models](https://arxiv.org/abs/2505.24864)
- (2025.05) [AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning](https://arxiv.org/abs/2505.16400)

### Asynchronous

- (2025.05) [AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning](https://arxiv.org/abs/2505.24298)

### Technical Report

- (2025.09) [CWM: An Open-Weights LLM for Research on Code Generation with World Models](https://ai.meta.com/research/publications/cwm-an-open-weights-llm-for-research-on-code-generation-with-world-models)
- (2025.09) [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883)
- (2025.08) [GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models](https://arxiv.org/abs/2508.06471)
- (2025.07) [Kimi K2: Open Agentic Intelligence](https://arxiv.org/abs/2507.20534)
- (2025.06) [Hunyuan-A13B Technical Report](https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/2798f3c8b6a69e0ce93950b0d2417203cf950fa0/report/Hunyuan_A13B_Technical_Report.pdf)
- (2025.06) [MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention](https://arxiv.org/abs/2506.13585)
- (2025.06) [Magistral](https://arxiv.org/abs/2506.10910)
- (2025.05) [Skywork Open Reasoner 1 Technical Report](https://arxiv.org/abs/2505.22312)
- (2025.05) [Qwen3 Technical Report](https://arxiv.org/abs/2505.09388)
- (2025.05) [Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org/abs/2505.00949)
- (2025.04) [Phi-4-reasoning Technical Report](https://arxiv.org/abs/2504.21318)
- (2025.04) [Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org/abs/2504.13914)
- (2025.01) [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)
- (2025.01) [Kimi k1.5: Scaling Reinforcement Learning with LLMs](https://arxiv.org/abs/2501.12599)

## Blogs

- (2025.09) [Towards Deterministic Inference in SGLang and Reproducible RL Training](https://lmsys.org/blog/2025-09-22-sglang-deterministic)
- (2025.09) [When Speed Kills Stability: Demystifying RL Collapse from the Training-Inference Mismatch](https://yingru.notion.site/When-Speed-Kills-Stability-Demystifying-RL-Collapse-from-the-Training-Inference-Mismatch-271211a558b7808d8b12d403fd15edda)
- (2025.09) [Defeating Nondeterminism in LLM Inference](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference)
- (2025.08) [ProRL V2 - Prolonged Training Validates RL Scaling Laws](https://hijkzzz.notion.site/prorl-v2)
- (2025.08) [Your Efficient RL Framework Secretly Brings You Off-Policy RL Training](https://fengyao.notion.site/off-policy-rl#279721e3f6c48092bbe2fcfe0e9c6b33)
- (2025.04) [DeepCoder: A Fully Open-Source 14B Coder at O3-mini Level](https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51)
- (2025.02) [DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2)

## Frameworks

- ![Stars](https://img.shields.io/github/stars/volcengine/verl?style=social)
  ![Forks](https://img.shields.io/github/forks/volcengine/verl?style=social)
  [verl](https://github.com/volcengine/verl)

- ![Stars](https://img.shields.io/github/stars/THUDM/slime?style=social)
  ![Forks](https://img.shields.io/github/forks/THUDM/slime?style=social)
  [slime](https://github.com/THUDM/slime)

- ![Stars](https://img.shields.io/github/stars/NVIDIA-NeMo/RL?style=social)
  ![Forks](https://img.shields.io/github/forks/NVIDIA-NeMo/RL?style=social)
  [Nemo RL](https://github.com/NVIDIA-NeMo/RL)

- ![Stars](https://img.shields.io/github/stars/PrimeIntellect-ai/prime-rl?style=social)
  ![Forks](https://img.shields.io/github/forks/PrimeIntellect-ai/prime-rl?style=social)
  [PRIME-RL](https://github.com/PrimeIntellect-ai/prime-rl)

- ![Stars](https://img.shields.io/github/stars/allenai/open-instruct?style=social)
  ![Forks](https://img.shields.io/github/forks/allenai/open-instruct?style=social)
  [Open Instruct](https://github.com/allenai/open-instruct)

- ![Stars](https://img.shields.io/github/stars/NovaSky-AI/SkyRL?style=social)
  ![Forks](https://img.shields.io/github/forks/NovaSky-AI/SkyRL?style=social)
  [SkyRL](https://github.com/NovaSky-AI/SkyRL)

- ![Stars](https://img.shields.io/github/stars/inclusionAI/AReaL?style=social)
  ![Forks](https://img.shields.io/github/forks/inclusionAI/AReaL?style=social)
  [AReaL](https://github.com/inclusionAI/AReaL)
