# Awesome-RL-Reasoning

[![PR Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen)](https://github.com/bruno686/Awesome-RL-based-LLM-Reasoning/pulls)
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

## Papers

### Algorithm

- (2025.12) [Stabilizing Reinforcement Learning with LLMs: Formulation and Practices](https://www.arxiv.org/abs/2512.01374), [Zheng+]
- (2025.10) [Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers](https://arxiv.org/abs/2510.11370), [Ma+]
- (2025.08) [Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning](https://arxiv.org/abs/2508.09726), [Shrivastava+]
- (2025.08) [Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://arxiv.org/abs/2508.08221), [Liu+]
- (2025.07) [Group Sequence Policy Optimization](https://arxiv.org/abs/2507.18071), [Zheng+]
- (2025.06) [Truncated Proximal Policy Optimization](https://arxiv.org/abs/2506.15050), [Fan+]
- (2025.04) [VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks](https://arxiv.org/abs/2504.05118), [Yue+]
- (2025.03) [Understanding R1-Zero-Like Training: A Critical Perspective](https://arxiv.org/abs/2503.20783), [Liu+, COLM 2025]
- (2025.03) [DAPO: An Open-Source LLM Reinforcement Learning System at Scale](https://arxiv.org/abs/2503.14476), [Yu+, NeurIPS 2025]
- (2024.02) [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300), [Shao+]

### Scaling

- (2025.10) [The Art of Scaling Reinforcement Learning Compute for LLMs](https://arxiv.org/abs/2510.13786), [Khatri+]
- (2025.06) [AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy](https://arxiv.org/abs/2506.13284), [Liu+]
- (2025.05) [ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models](https://arxiv.org/abs/2505.24864), [Liu+, NeurIPS 2025]
- (2025.05) [AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning](https://arxiv.org/abs/2505.16400), [Chen+, NeurIPS 2025]

### Asynchronous

- (2025.09) [PipelineRL: Faster On-policy Reinforcement Learning for Long Sequence Generation](https://arxiv.org/abs/2509.19128), [Piché+]
- (2025.05) [AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning](https://arxiv.org/abs/2505.24298), [Fu+, NeurIPS 2025]

### Technical Report

- (2025.12) [MiMo-V2-Flash Technical Report](https://github.com/XiaomiMiMo/MiMo-V2-Flash/blob/main/paper.pdf), [LLM-Core Xiaomi]
- (2025.11) [Olmo 3](https://www.datocms-assets.com/64837/1763662397-1763646865-olmo_3_technical_report-1.pdf), [Olmo Team]
- (2025.10) [Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model](https://arxiv.org/abs/2510.18855), [Ling Team]
- (2025.09) [DeepSeek-V3.2-Exp: Boosting Long-Context Efficiency with DeepSeek Sparse Attention](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/2305c7ec3bf4b357dc0aee8dd97e0a1cbc0ea0e1/DeepSeek_V3_2.pdf), [DeepSeek-AI]
- (2025.09) [CWM: An Open-Weights LLM for Research on Code Generation with World Models](https://ai.meta.com/research/publications/cwm-an-open-weights-llm-for-research-on-code-generation-with-world-models), [Meta FAIR CodeGen Team]
- (2025.09) [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883), [Meituan LongCat Team]
- (2025.08) [GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models](https://arxiv.org/abs/2508.06471), [GLM-4.5 Team]
- (2025.07) [Kimi K2: Open Agentic Intelligence](https://arxiv.org/abs/2507.20534), [Kimi Team]
- (2025.06) [Hunyuan-A13B Technical Report](https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/2798f3c8b6a69e0ce93950b0d2417203cf950fa0/report/Hunyuan_A13B_Technical_Report.pdf), [Tencent Hunyuan Team]
- (2025.06) [MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention](https://arxiv.org/abs/2506.13585), [MiniMax]
- (2025.06) [Magistral](https://arxiv.org/abs/2506.10910), [Mistral-AI]
- (2025.05) [Skywork Open Reasoner 1 Technical Report](https://arxiv.org/abs/2505.22312), [Skywork AI]
- (2025.05) [Qwen3 Technical Report](https://arxiv.org/abs/2505.09388), [Qwen Team]
- (2025.05) [Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org/abs/2505.00949), [NVIDIA]
- (2025.04) [Phi-4-reasoning Technical Report](https://arxiv.org/abs/2504.21318), [Microsoft]
- (2025.04) [Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org/abs/2504.13914), [ByteDance Seed]
- (2025.01) [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948), [DeepSeek-AI]
- (2025.01) [Kimi k1.5: Scaling Reinforcement Learning with LLMs](https://arxiv.org/abs/2501.12599), [Kimi Team]

## Blogs

### Deterministic and Reproducibility

- (2025.11) [No More Train-Inference Mismatch: Bitwise Consistent On-Policy Reinforcement Learning with vLLM and TorchTitan](https://blog.vllm.ai/2025/11/10/bitwise-consistent-train-inference.html), [vLLM and TorchTitan Teams]
- (2025.09) [Towards Deterministic Inference in SGLang and Reproducible RL Training](https://lmsys.org/blog/2025-09-22-sglang-deterministic), [The SGLang Team]
- (2025.09) [Defeating Nondeterminism in LLM Inference](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference), [Horace He and Thinking Machines Lab]

### Training–Inference Mismatch

- (2025.09) [When Speed Kills Stability: Demystifying RL Collapse from the Training-Inference Mismatch](https://yingru.notion.site/When-Speed-Kills-Stability-Demystifying-RL-Collapse-from-the-Training-Inference-Mismatch-271211a558b7808d8b12d403fd15edda), [Liu+]
- (2025.08) [Your Efficient RL Framework Secretly Brings You Off-Policy RL Training](https://fengyao.notion.site/off-policy-rl#279721e3f6c48092bbe2fcfe0e9c6b33), [Yao+]

### Scaling and Open-Source

- (2025.08) [ProRL V2 - Prolonged Training Validates RL Scaling Laws](https://hijkzzz.notion.site/prorl-v2), [Hu+]
- (2025.04) [DeepCoder: A Fully Open-Source 14B Coder at O3-mini Level](https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51), [Agentica x Together AI]
- (2025.02) [DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2), [Luo+]

## Frameworks

- ![Stars](https://img.shields.io/github/stars/volcengine/verl?style=social)
  ![Forks](https://img.shields.io/github/forks/volcengine/verl?style=social)
  [verl](https://github.com/volcengine/verl)

- ![Stars](https://img.shields.io/github/stars/THUDM/slime?style=social)
  ![Forks](https://img.shields.io/github/forks/THUDM/slime?style=social)
  [slime](https://github.com/THUDM/slime)

- ![Stars](https://img.shields.io/github/stars/NVIDIA-NeMo/RL?style=social)
  ![Forks](https://img.shields.io/github/forks/NVIDIA-NeMo/RL?style=social)
  [Nemo RL](https://github.com/NVIDIA-NeMo/RL)

- ![Stars](https://img.shields.io/github/stars/PrimeIntellect-ai/prime-rl?style=social)
  ![Forks](https://img.shields.io/github/forks/PrimeIntellect-ai/prime-rl?style=social)
  [PRIME-RL](https://github.com/PrimeIntellect-ai/prime-rl)

- ![Stars](https://img.shields.io/github/stars/allenai/open-instruct?style=social)
  ![Forks](https://img.shields.io/github/forks/allenai/open-instruct?style=social)
  [Open Instruct](https://github.com/allenai/open-instruct)

- ![Stars](https://img.shields.io/github/stars/NovaSky-AI/SkyRL?style=social)
  ![Forks](https://img.shields.io/github/forks/NovaSky-AI/SkyRL?style=social)
  [SkyRL](https://github.com/NovaSky-AI/SkyRL)

- ![Stars](https://img.shields.io/github/stars/inclusionAI/AReaL?style=social)
  ![Forks](https://img.shields.io/github/forks/inclusionAI/AReaL?style=social)
  [AReaL](https://github.com/inclusionAI/AReaL)

- ![Stars](https://img.shields.io/github/stars/ServiceNow/PipelineRL?style=social)
  ![Forks](https://img.shields.io/github/forks/ServiceNow/PipelineRL?style=social)
  [PipelineRL](https://github.com/ServiceNow/PipelineRL)

- ![Stars](https://img.shields.io/github/stars/radixark/miles?style=social)
  ![Forks](https://img.shields.io/github/forks/radixark/miles?style=social)
  [miles](https://github.com/radixark/miles)
